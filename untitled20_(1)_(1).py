# -*- coding: utf-8 -*-
"""Untitled20 (1) (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/126OS6Hmtaw0RKnoXFztyppXVI5Pxi32l
"""

!pip install pdf2image
!apt-get install poppler-utils # Install Poppler on the system

from pdf2image import convert_from_path
import os

# Convert PDF to images
def pdf_to_images(pdf_path, output_folder="/content/extracted_images"): # Changed to an absolute path within Colab
    os.makedirs(output_folder, exist_ok=True)
    pages = convert_from_path(pdf_path, dpi=300)  # High-resolution extraction

    image_paths = []
    for i, page in enumerate(pages):
        img_path = os.path.join(output_folder, f"page_{i}.png")
        page.save(img_path, "PNG")
        image_paths.append(img_path)

    print(f"Extracted {len(image_paths)} images from {pdf_path}")
    return image_paths

# Run the function
pdf_path = "/content/Test (1).pdf"
image_paths = pdf_to_images(pdf_path)

import cv2
import numpy as np

def preprocess_image(image_path, output_folder="processed_images"):
    os.makedirs(output_folder, exist_ok=True)

    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale

    # Apply adaptive thresholding to enhance lines
    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY, 11, 2)

    # Edge detection using Canny
    edges = cv2.Canny(thresh, 50, 150)

    processed_path = os.path.join(output_folder, os.path.basename(image_path))
    cv2.imwrite(processed_path, edges)  # Save processed image

    return processed_path

# Run preprocessing on extracted images
processed_images = [preprocess_image(img) for img in image_paths]
print(f"Processed {len(processed_images)} images.")

def detect_pipelines(image_path, output_folder="pipeline_detected"):
    os.makedirs(output_folder, exist_ok=True)

    img = cv2.imread(image_path)
    edges = cv2.Canny(img, 50, 150, apertureSize=3)

    # Detect lines using Hough Transform
    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100, minLineLength=50, maxLineGap=5)

    img_copy = img.copy()

    if lines is not None:
        for line in lines:
            x1, y1, x2, y2 = line[0]
            cv2.line(img_copy, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Draw pipelines

    detected_path = os.path.join(output_folder, os.path.basename(image_path))
    cv2.imwrite(detected_path, img_copy)

    return detected_path

# Run pipeline detection
pipeline_detected_images = [detect_pipelines(img) for img in processed_images]
print(f"Detected pipelines in {len(pipeline_detected_images)} images.")

import torch
import torchvision
from torchvision import transforms
from torchvision.models.detection import fasterrcnn_resnet50_fpn

# Load pre-trained Faster R-CNN
def load_rcnn_model():
    model = fasterrcnn_resnet50_fpn(pretrained=True)
    model.eval()
    return model

def detect_instruments(image_path, model, output_folder="ic_detected"):
    os.makedirs(output_folder, exist_ok=True)

    img = cv2.imread(image_path)
    transform = transforms.Compose([transforms.ToTensor()])
    img_tensor = transform(img).unsqueeze(0)

    # Perform inference
    with torch.no_grad():
        prediction = model(img_tensor)

    img_copy = img.copy()
    for i, box in enumerate(prediction[0]['boxes']):
        score = prediction[0]['scores'][i].item()
        if score > 0.5:  # Confidence threshold
            x1, y1, x2, y2 = map(int, box)
            cv2.rectangle(img_copy, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Draw red boxes for I&C
            cv2.putText(img_copy, "I&C", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

    detected_path = os.path.join(output_folder, os.path.basename(image_path))
    cv2.imwrite(detected_path, img_copy)

    return detected_path

# Load model and run I&C detection
rcnn_model = load_rcnn_model()
ic_detected_images = [detect_instruments(img, rcnn_model) for img in pipeline_detected_images]
print(f"Detected I&C elements in {len(ic_detected_images)} images.")

!apt-get install tesseract-ocr
!apt-get install libtesseract-dev

import pytesseract
import cv2
import os

# Set Tesseract path (if not in your system's PATH)
# This is usually necessary in Colab
pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract' # Modify if Tesseract is installed in a different location

def extract_text(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    text = pytesseract.image_to_string(img, config="--psm 6")  # Extract text
    return text.strip()

# Run OCR on I&C detected images
for img in ic_detected_images:
    extracted_text = extract_text(img)
    print(f"Text from {img}: {extracted_text}")

import os
import cv2
import torch
import json
import torchvision
from torchvision import transforms
from torchvision.models.detection import fasterrcnn_resnet50_fpn

# Load pre-trained Faster R-CNN model
def load_rcnn_model():
    model = fasterrcnn_resnet50_fpn(pretrained=True)
    model.eval()
    return model

# Function to extract pipeline structure from IC detected images
def extract_pipeline_structure(image_path, model, output_folder="pipeline_extraction"):
    os.makedirs(output_folder, exist_ok=True)

    # Load image and convert to tensor
    img = cv2.imread(image_path)
    transform = transforms.Compose([transforms.ToTensor()])
    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension

    # Perform inference
    with torch.no_grad():
        prediction = model(img_tensor)

    # Extract pipeline elements and connections
    pipeline_elements = []
    img_copy = img.copy()

    for i, box in enumerate(prediction[0]['boxes']):
        score = prediction[0]['scores'][i].item()
        if score > 0.5:  # Confidence threshold
            x1, y1, x2, y2 = map(int, box)
            width, height = x2 - x1, y2 - y1

            # Save element info
            element = {
                "id": i,
                "coordinates": {"x": x1, "y": y1, "width": width, "height": height},
                "confidence": round(score, 2)
            }
            pipeline_elements.append(element)

            # Draw bounding box
            cv2.rectangle(img_copy, (x1, y1), (x2, y2), (0, 255, 0), 2)

    # Save the extracted image
    extracted_path = os.path.join(output_folder, os.path.basename(image_path).replace(".png", "_extracted.png"))
    cv2.imwrite(extracted_path, img_copy)

    return pipeline_elements

# Function to process all images in IC detected folder
def process_ic_detection_folder(ic_detected_folder):
    print("Loading Faster R-CNN model...")
    model = load_rcnn_model()

    print("Extracting pipeline structure and connections...")
    image_paths = [os.path.join(ic_detected_folder, img) for img in os.listdir(ic_detected_folder) if img.endswith(".png")]

    all_pipeline_data = {}
    for img_path in image_paths:
        img_name = os.path.basename(img_path)
        all_pipeline_data[img_name] = extract_pipeline_structure(img_path, model)

    # Save pipeline structure as JSON
    json_output = os.path.join("pipeline_extraction", "pipeline_structure.json")
    os.makedirs("pipeline_extraction", exist_ok=True)
    with open(json_output, "w") as json_file:
        json.dump(all_pipeline_data, json_file, indent=4)

    print(f"Pipeline structure extracted. Results saved in 'pipeline_extraction' folder.")

# Set the IC detected image folder path
ic_detected_folder = "ic_detected"  # Update with your actual folder name
process_ic_detection_folder(ic_detected_folder)

import os

ic_detected_folder = "ic_detected"

# List all images
ic_images = [os.path.join(ic_detected_folder, img) for img in os.listdir(ic_detected_folder) if img.endswith(('.png', '.jpg', '.jpeg'))]

print(f"✅ Found {len(ic_images)} images: {ic_images}")

import cv2
import os

def extract_ic_positions(image_path):
    """Extracts I&C element positions using contours (bounding boxes)."""
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    if img is None:
        print(f"❌ Error: Cannot read image {image_path}")
        return []

    # Apply threshold to detect shapes
    _, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)

    # Find contours of detected objects
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    ic_positions = []
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        center_x, center_y = x + w // 2, y + h // 2
        ic_positions.append((center_x, center_y))  # Store center of bounding box

    return ic_positions

# Extract I&C positions from all detected images
ic_detected_folder = "ic_detected"
ic_images = [os.path.join(ic_detected_folder, img) for img in os.listdir(ic_detected_folder) if img.endswith(".png")]

ic_all_positions = {img: extract_ic_positions(img) for img in ic_images}

print("✅ Extracted I&C positions for all images:", ic_all_positions)

import numpy as np

def validate_ic_connections(ic_positions, pipeline_positions, threshold=20):
    """Checks if each I&C element is close to a pipeline segment."""
    valid_connections = []
    invalid_connections = []

    for ic_x, ic_y in ic_positions:
        # Check if any pipeline point is within the threshold distance
        distances = [np.sqrt((px - ic_x) ** 2 + (py - ic_y) ** 2) for px, py in pipeline_positions]
        min_distance = min(distances) if distances else float("inf")

        if min_distance < threshold:
            valid_connections.append((ic_x, ic_y))
        else:
            invalid_connections.append((ic_x, ic_y))

    return valid_connections, invalid_connections

# Validate connections for all images
validation_results = {}
for img, ic_positions in ic_all_positions.items():
    valid, invalid = validate_ic_connections(ic_positions, pipeline_positions)
    validation_results[img] = {"valid": valid, "invalid": invalid}

print("✅ Validation Results:", validation_results)

import cv2
import numpy as np
import json
import os

def preprocess_image(image_path):
    """Load and preprocess image to enhance pipeline detection."""
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    blurred = cv2.GaussianBlur(img, (5, 5), 0)
    edges = cv2.Canny(blurred, 50, 150)
    return edges

def detect_contours(image_path):
    """Find contours in an image representing pipeline structures."""
    edges = preprocess_image(image_path)
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    return contours

def extract_coordinates(contours):
    """Extract geometric coordinates from contours."""
    coordinates = [contour.reshape(-1, 2).tolist() for contour in contours]
    return coordinates

def process_images(image_folder):
    """Process all images in a folder and extract pipeline structures."""
    pipeline_data = {}
    for filename in os.listdir(image_folder):
        if filename.endswith(('.png', '.jpg', '.jpeg')):
            image_path = os.path.join(image_folder, filename)
            contours = detect_contours(image_path)
            pipeline_data[filename] = extract_coordinates(contours)

    return pipeline_data

# Define image folder path
image_folder = "/content/ic_detected"

# Process images and extract pipeline structure
pipeline_structure = process_images(image_folder)

# Save extracted pipeline structures as JSON
output_json_path = "pipeline_structure.json"
with open(output_json_path, "w") as json_file:
    json.dump(pipeline_structure, json_file, indent=4)

print(f"Pipeline structure saved to {output_json_path}")

import json

# Load the extracted pipeline structure
json_path = "pipeline_structure.json"

with open(json_path, "r") as file:
    pipeline_data = json.load(file)

# Print a sample to verify correctness
print(json.dumps(pipeline_data, indent=4))

import cv2
import json
import os
import numpy as np
import matplotlib.pyplot as plt

# Load JSON pipeline data
with open("pipeline_structure.json", "r") as f:
    pipeline_data = json.load(f)

image_folder = "/content/ic_detected"

for image_name, contours in pipeline_data.items():
    image_path = os.path.join(image_folder, image_name)

    img = cv2.imread(image_path)

    if img is None:
        print(f"Error loading {image_name}")
        continue

    for contour in contours:
        contour = np.array(contour, dtype=np.int32)
        cv2.polylines(img, [contour], isClosed=False, color=(0, 0, 255), thickness=2)

    # Convert to RGB for displaying in Matplotlib
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Display image with Matplotlib
    plt.figure(figsize=(8, 6))
    plt.imshow(img_rgb)
    plt.title(f"Pipeline Structure - {image_name}")
    plt.axis("off")
    plt.show()

import cv2
import json
import os
import numpy as np
from google.colab.patches import cv2_imshow  # Use this in Colab

# Load JSON pipeline data
with open("pipeline_structure.json", "r") as f:
    pipeline_data = json.load(f)

image_folder = "/content/ic_detected"

for image_name, contours in pipeline_data.items():
    image_path = os.path.join(image_folder, image_name)

    img = cv2.imread(image_path)

    if img is None:
        print(f"Error loading {image_name}")
        continue

    for contour in contours:
        contour = np.array(contour, dtype=np.int32)
        cv2.polylines(img, [contour], isClosed=False, color=(0, 0, 255), thickness=2)

    # Display image in Colab
    cv2_imshow(img)  # ✅ Replaces cv2.imshow()

import json
import fitz  # PyMuPDF
import cv2
import numpy as np
from PIL import Image
import io

# Load extracted pipeline structure
with open("pipeline_structure.json", "r") as f:
    pipeline_data = json.load(f)

# Load the PDF
pdf_path = "Test (1).pdf"
doc = fitz.open(pdf_path)

# Process each page
for page_num in range(len(doc)):
    page = doc[page_num]
    pix = page.get_pixmap()

    img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.h, pix.w, pix.n)
    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)

    # Draw pipelines on the PDF image
    for image_name, contours in pipeline_data.items():
        for contour in contours:
            contour = np.array(contour, dtype=np.int32)
            cv2.polylines(img, [contour], isClosed=False, color=(255, 0, 0), thickness=2)

    # Convert OpenCV image to PIL Image
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    pil_img = Image.fromarray(img_rgb)

    # Save PIL image to a bytes buffer
    img_byte_arr = io.BytesIO()
    pil_img.save(img_byte_arr, format="PNG")
    img_byte_arr = img_byte_arr.getvalue()  # Get bytes

    # Insert image into PDF
    rect = page.rect  # Full-page insertion
    page.insert_image(rect, stream=img_byte_arr)

# Save the updated PDF
annotated_pdf_path = "Annotated_Pipeline_Structure.pdf"
doc.save(annotated_pdf_path)
doc.close()

print(f"✅ Annotated PDF saved as {annotated_pdf_path}")

import cv2
import json
import os
import numpy as np
import matplotlib.pyplot as plt

# Load JSON pipeline data
with open("pipeline_structure.json", "r") as f:
    pipeline_data = json.load(f)

image_folder = "/content/ic_detected"
output_folder = "/content/pipeline_output"

# Create output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

for image_name, contours in pipeline_data.items():
    image_path = os.path.join(image_folder, image_name)

    img = cv2.imread(image_path)

    if img is None:
        print(f"Error loading {image_name}")
        continue

    for contour in contours:
        contour = np.array(contour, dtype=np.int32)
        cv2.polylines(img, [contour], isClosed=False, color=(0, 0, 255), thickness=2)

    # Convert to RGB for displaying in Matplotlib
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Save the output image
    output_path = os.path.join(output_folder, image_name)
    cv2.imwrite(output_path, cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR))

    # Display image with Matplotlib (Optional)
    plt.figure(figsize=(8, 6))
    plt.imshow(img_rgb)
    plt.title(f"Pipeline Structure - {image_name}")
    plt.axis("off")
    plt.show()

print(f"✅ All output images are saved in: {output_folder}")

import cv2
import pytesseract
import os
import numpy as np
import json

# Paths
reference_image_path = "/content/reference image.jpg"  # First image with symbols and labels
image_folder = "/content/pipeline_output"  # Folder with pipeline images
output_folder = "tagged_images"
os.makedirs(output_folder, exist_ok=True)

# Load reference image
ref_img = cv2.imread(reference_image_path)
gray_ref = cv2.cvtColor(ref_img, cv2.COLOR_BGR2GRAY)

# Use OCR to extract text labels from reference image
pytesseract.pytesseract.tesseract_cmd = r"/usr/bin/tesseract"  # Adjust path if needed
custom_config = r'--oem 3 --psm 6'
extracted_text = pytesseract.image_to_string(gray_ref, config=custom_config)

# Placeholder function to detect symbols in reference image
def detect_symbols(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY_INV)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    return contours

# Extract symbols from reference image
reference_symbols = detect_symbols(ref_img)

# Process each image in the folder
for image_name in os.listdir(image_folder):
    image_path = os.path.join(image_folder, image_name)
    img = cv2.imread(image_path)
    if img is None:
        print(f"Error loading {image_name}")
        continue

    # Detect symbols in the pipeline image
    detected_symbols = detect_symbols(img)

    # Match detected symbols with reference symbols (placeholder logic)
    for i, symbol in enumerate(detected_symbols):
        x, y, w, h = cv2.boundingRect(symbol)
        label = f"Component {i+1}"  # Placeholder matching logic
        cv2.putText(img, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)

    # Save the annotated image
    output_path = os.path.join(output_folder, image_name)
    cv2.imwrite(output_path, img)

print(f"All tagged images saved in {output_folder}")